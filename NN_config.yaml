name: siam #e siam_eu
width: 512
height: 324 #asi
batch_size_eval: 1 #32
batch_size_train: 50
epochs: 4 #prolly indexes from 0!
lr: 6 #e4.1 #10e-6  the lareget this numebr is the slower it is learning
eval_rate: 2 #e3 ## should be whole divisor of epochs
crop_sizes: [56] #e56
fraction: 8 #e8
smoothness: 2
negative_frac: 0.333
layer_pool: True
filter_size: 3
emb_channels: 16
residual: 0 #e:0e
crops_multiplier: 1
batching: crops_multiplier
eval_limit: 20000000000000
tolerance: 50
use_cache: False
save_cache: False
limit: null
all_combos: True
old: False
train:
  help:
eval:
  help: 30
plot_training: False
plot_eval_in_train: False
plot_eval: False
#tolerance: 32

